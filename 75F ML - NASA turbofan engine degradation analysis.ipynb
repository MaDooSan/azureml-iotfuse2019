{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Turbofan Engine Degradation Analysis - IoTFuse 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the required libraries using `pip install`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib==1.5.1\n",
    "!pip install pandas==0.18.1\n",
    "!pip install numpy==1.11.3\n",
    "!pip install seaborn==0.7.1\n",
    "!pip install numexpr==2.6.1\n",
    "!pip install scikit-learn==0.18.1\n",
    "!pip install plotly==3.1.0\n",
    "\n",
    "'''\n",
    "!pip install -U matplotlib\n",
    "!pip install pandas==0.18.1\n",
    "!pip install numpy==1.11.3\n",
    "!pip install seaborn==0.7.1\n",
    "!pip install numexpr\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "#plotly.tools.set_credentials_file(username='[PLOTLY USERNAME]', api_key='[PLOTLY API KEY]')\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (16, 16)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# load necessary packages and view available data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "np.random.seed(7)  \n",
    "from sklearn import ensemble\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1a: Load the datasets from the workspace\n",
    "\n",
    "- if you're using Notebooks on Azure ML Studio, use the following to load your dataset\n",
    "- make sure you've uploaded the data to your workspace first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml\n",
    "from azureml import Workspace\n",
    "ws = Workspace()\n",
    "trainData = ws.datasets['RUL_train_FD001.csv'].to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1b: Load a local dataset\n",
    "\n",
    "- if you're working locally, use the following to load your dataset\n",
    "- make sure you're pointing to the directory where the data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('CMAPSSData/raw_data/train_FD001.txt', sep=\" \", header=None)\n",
    "testData = pd.read_csv('CMAPSSData/raw_data/test_FD001.txt', sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Transform your data\n",
    "\n",
    "- Delete any null columns\n",
    "- Set datatypes\n",
    "- Change column names to something more readable\n",
    "- Calculate Remaining Useful Life (RUL)\n",
    "- Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Delete any null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(trainData.columns[[26, 27]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Set datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Change column names to something more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexCols =  [\"UnitNumber\",\"Cycle\"]\n",
    "operationalSettingCols = [\"Setting1\",\"Setting2\",\"Setting3\"]\n",
    "sensorCols =['FanInletTemp','LPCOutletTemp','HPCOutletTemp','LPTOutletTemp','FanInletPres','BypassDuctPres','TotalHPCOutletPres','PhysFanSpeed','PhysCoreSpeed','EnginePresRatio','StaticHPCOutletPres','FuelFlowRatio','CorrFanSpeed','CorrCoreSpeed','BypassRatio','BurnerFuelAirRatio','BleedEnthalpy','DemandFanSpeed','DemandCorrFanSpeed','HPTCoolantBleed','LPTCoolantBleed']\n",
    "cols = indexCols + operationalSettingCols + sensorCols\n",
    "\n",
    "trainData.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = trainData[trainData.UnitNumber<5].groupby(\"UnitNumber\")\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 36}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['figure.figsize'] = [14,10]\n",
    "\n",
    "plt.ylabel('HPCOutletTemp',fontsize=18)\n",
    "plt.xlabel('Cycles',fontsize=18)\n",
    "for i,g in grouped:\n",
    "    plt.plot(g['Cycle'], g['HPCOutletTemp'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Calculate Remaining Useful Life (RUL)\n",
    "\n",
    "- group the data by `UnitNumber`\n",
    "- evaluate the maximum number of cycles and create a new column called `MaxCycles`\n",
    "- calculate `RUL` for every instance: RUL(t) = MaxCycles - Cycle(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxCycles = trainData.groupby('UnitNumber')['Cycle'].max().reset_index()\n",
    "maxCycles.columns = ['UnitNumber', 'MaxCycles']\n",
    "mergedTrain = trainData.merge(maxCycles, left_on='UnitNumber', right_on='UnitNumber', how='inner')\n",
    "mergedTrain.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUL = mergedTrain[\"MaxCycles\"] - mergedTrain[\"Cycle\"]\n",
    "trainData = mergedTrain[\"RUL\"] = RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns\n",
    "trainData = mergedTrain.drop(\"MaxCycles\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data visualization\n",
    "\n",
    "- Investigate how features vary with RUL\n",
    "- Investigate how features vary under the different Operational Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize how features vary with RUL\n",
    "featurePlot = sns.PairGrid(data=trainData.query('UnitNumber < 15'),\n",
    "                       x_vars='RUL',\n",
    "                       y_vars=operationalSettingCols+sensorCols,\n",
    "                       hue=\"UnitNumber\", size=5, aspect=2)\n",
    "featurePlot = featurePlot.map(plt.scatter, alpha=0.5)\n",
    "featurePlot = featurePlot.set(xlim=(400,0))\n",
    "featurePlot = featurePlot.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "OpSettingsPlot = sns.pairplot(data=trainData.query('UnitNumber < 15'),\n",
    "                              x_vars=operationalSettingCols,\n",
    "                              y_vars=sensorCols,\n",
    "                              hue=\"UnitNumber\", size=4, aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Feature Extraction\n",
    "\n",
    "- Remove features that can potentially cause target leakage\n",
    "- Evaluate feature importance using random forest regression\n",
    "- Remove redundant features based on above analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Remove features that can potentially cause target leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leakageCols = ['UnitNumber', 'Cycle', 'Setting1', 'Setting2', 'Setting3']  \n",
    "leakageDroppedTrainData = trainData.drop(leakageCols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Evaluate feature importance using random forest regression\n",
    "\n",
    "- Using a random forests is a quick and dirty way to do feature-ranking\n",
    "- However, be aware of some gotchas, especially when interpreting this data\n",
    "- Example: if 2 features with similar significance are highly correlated, one might not show up as a significant feature\n",
    "- Useful link: https://blog.datadive.net/selecting-good-features-part-iii-random-forests/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up features and target variable \n",
    "FIY = leakageDroppedTrainData['RUL']\n",
    "FIX = leakageDroppedTrainData.drop(['RUL'], axis = 1)\n",
    "\n",
    "randomForestRegressor = ensemble.RandomForestRegressor(max_features=2, n_estimators = 200, max_depth = 20)\n",
    "randomForestRegressor.fit(FIX, FIY)\n",
    "predY = randomForestRegressor.predict(FIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph feature importance\n",
    "featureImportance = randomForestRegressor.feature_importances_\n",
    "featureIDs = np.argsort(featureImportance)[::-1]\n",
    "featureNames = FIX.columns    \n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "plt.title(\"Feature Importance\", fontsize = 20)\n",
    "plt.bar(range(FIX.shape[1]), featureImportance[featureIDs], color=\"b\", align=\"center\")\n",
    "labelSet = {id:label for id,label in zip(range(len(featureNames)),featureNames)}\n",
    "plt.xticks(range(FIX.shape[1]), [labelSet[id] for id in featureIDs])\n",
    "plt.xticks(rotation=-60)\n",
    "plt.xlim([-1, FIX.shape[1]])\n",
    "plt.ylabel(\"Feature Importance Score\", fontsize = 18)\n",
    "plt.xlabel(\"Feature\", fontsize = 18)\n",
    "plt.show()\n",
    "# list feature importance\n",
    "important_features = pd.Series(data=randomForestRegressor.feature_importances_,index=FIX.columns)\n",
    "important_features.sort_values(ascending=False,inplace=True)\n",
    "display(important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Remove redundant features based on above analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundantCols = list(important_features[important_features<0.0001].index)\n",
    "print(redundantCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Solve a Regression Problem\n",
    "\n",
    "- can we predict RUL (in cycles)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Prepare data prior to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regTrainData = leakageDroppedTrainData.drop(redundantCols, axis = 1)\n",
    "\n",
    "# impute data if needed\n",
    "\n",
    "numericData = regTrainData.select_dtypes(exclude=['object'])\n",
    "for col in numericData.columns:\n",
    "    if pd.isnull(numericData[col]).sum() > 0:\n",
    "        numericData[\"%s_mi\" % (col)] = pd.isnull(numericData[col])\n",
    "        median = numericData[col].median()\n",
    "        numericData[col] = numericData[col].apply(lambda x: median if pd.isnull(x) else x)\n",
    "\n",
    "# set up features and target variable \n",
    "\n",
    "RY = numericData['RUL']\n",
    "RX = numericData.drop(['RUL'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Train a Random Forest Regression\n",
    "\n",
    "- Fast and easy to train\n",
    "- Minimal feature engineering / transformation required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regression\n",
    "trainX, testX, trainY, testY = train_test_split(RX, RY, test_size=0.2, random_state=7)\n",
    "\n",
    "randomForestRegressor = ensemble.RandomForestRegressor()\n",
    "pipeline = Pipeline(steps=[('standardize', preprocessing.StandardScaler()),\n",
    "                           ('model', randomForestRegressor) ])\n",
    "# model tuning\n",
    "test_min_samples_leaf = [2, 10, 25, 50, 100]\n",
    "test_max_depth = [7, 8, 9, 10, 11, 12]\n",
    "# run the model using gridsearch, select the model with best search\n",
    "optimizedRandomForestRegressor = GridSearchCV(estimator=pipeline,\n",
    "                                              cv=model_selection.KFold(5),\n",
    "                                              param_grid=dict(model__min_samples_leaf = test_min_samples_leaf, model__max_depth = test_max_depth),\n",
    "                                              scoring = 'neg_mean_squared_error',\n",
    "                                              verbose = 1,\n",
    "                                              n_jobs = -1)\n",
    "optimizedRandomForestRegressor.fit(trainX, trainY)\n",
    "print(optimizedRandomForestRegressor.best_estimator_)\n",
    "predY = optimizedRandomForestRegressor.predict(testX)\n",
    "print(\"Mean Squared Error: \", mean_squared_error(testY, predY))\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(testY, predY))\n",
    "print(\"Coefficient of Determination (R2): \", r2_score(testY, predY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Plot actual vs. predicted Remaining Useful Lifetime (RUL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot actual vs predicted Remaining Useful Life\n",
    "trace0 = go.Scatter(\n",
    "    x = testY,\n",
    "    y = predY,\n",
    "    mode = 'markers',\n",
    "    name = 'RUL',\n",
    "    marker = dict(color='rgb(22, 96, 167)')\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = testY,\n",
    "    y = testY,\n",
    "    name = 'Reference',\n",
    "    line = dict(\n",
    "        color = ('rgba(0, 0, 0, 0.2)'),\n",
    "        width = 4,\n",
    "        dash = 'dash')\n",
    ")\n",
    "data = [trace1,trace0]\n",
    "layout = go.Layout(\n",
    "    title = 'Actual vs. Predicted Useful Remaining Life (Cycles)',\n",
    "    xaxis=dict(title='Actual Remaining Useful Life'),\n",
    "    yaxis=dict(title='Predicted Remaining Useful Life'))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Solve a Classification Problem\n",
    "\n",
    "- can we identify when unit is within its last 15 cycles?\n",
    "- check the frequency of class occurrences: what do you see?\n",
    "- how do we remedy this? (this is actually not covered here; I will link to some useful articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Prepare data prior to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryTrainData = leakageDroppedTrainData.drop(redundantCols, axis = 1)\n",
    "binaryTrainData['15_Cycles'] = np.where(binaryTrainData['RUL'] <= 15, 1, 0 )\n",
    "binaryTrainData = binaryTrainData.drop('RUL', axis = 1)\n",
    "# impute data if needed\n",
    "numericData = binaryTrainData.select_dtypes(exclude=['object'])\n",
    "for col in numericData.columns:\n",
    "    if pd.isnull(numericData[col]).sum() > 0:\n",
    "        numericData[\"%s_mi\" % (col)] = pd.isnull(numericData[col])\n",
    "        median = numericData[col].median()\n",
    "        numericData[col] = numericData[col].apply(lambda x: median if pd.isnull(x) else x)\n",
    "BY = numericData['15_Cycles']\n",
    "BX = numericData.drop(['15_Cycles'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classification\n",
    "trainX, testX, trainY, testY = train_test_split(BX, BY, test_size=0.2, random_state=7)\n",
    "randomForestClassifier = ensemble.RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('standardize', preprocessing.StandardScaler()),\n",
    "                           ('model', randomForestClassifier) ])\n",
    "# model tuning\n",
    "test_min_samples_leaf = [2, 25, 50]\n",
    "test_max_depth = [8, 9, 10, 12]\n",
    "# run the model using gridsearch, select the model with best search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "optimizedRandomForestClassifier = GridSearchCV(estimator=pipeline,\n",
    "                            cv=model_selection.KFold(5),\n",
    "                            param_grid =dict(model__min_samples_leaf = test_min_samples_leaf, model__max_depth = test_max_depth),\n",
    "                            scoring = 'roc_auc',\n",
    "                            verbose = 1,\n",
    "                            n_jobs = -1)\n",
    "optimizedRandomForestClassifier.fit(trainX, trainY)\n",
    "predY = optimizedRandomForestClassifier.predict(testX)\n",
    "predYProb = optimizedRandomForestClassifier.predict_proba(testX)[:, 1]\n",
    "print(optimizedRandomForestClassifier.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title,fontsize=18)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Actual label',fontsize=18)\n",
    "    plt.xlabel('Predicted label',fontsize=18)\n",
    "    plt.tight_layout()\n",
    "\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['figure.figsize'] = [10,10]\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "confusionMatrix = confusion_matrix(testY, predY)\n",
    "plot_confusion_matrix(confusionMatrix, normalize = True, classes=[\"No failure (N)\",\"Failure within 15 days (P)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Evaluate Precision and Recall\n",
    "\n",
    "- accuracy may not give us the whole picture\n",
    "- precision, recall and F1-score are better metrics\n",
    "\n",
    "![alt-text-1](content/precision_recall.png \"Precision & Recall\") ![alt-text-2](content/precision_recall_example.png \"Precision & Recall Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisionScore = precision_score(testY, predY)\n",
    "accuracyScore = accuracy_score(testY, predY)\n",
    "recallScore = recall_score(testY, predY)\n",
    "print(\"Precision: \"+\"{:.1%}\".format(precisionScore))\n",
    "print(\"Accuracy: \"+\"{:.1%}\".format(accuracyScore))\n",
    "print(\"Recall: \"+\"{:.1%}\".format(recallScore))\n",
    "print(classification_report(testY, predY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Plot ROC curve\n",
    "\n",
    "- helps us visualize the performance of a binary classifier\n",
    "- http://www.navan.name/roc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(testY, predYProb)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "trace0 = go.Scatter(\n",
    "    x = fpr,\n",
    "    y = tpr,\n",
    "    mode = 'lines',\n",
    "    name = 'AUC = %0.2f' % roc_auc,\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = [0,1],\n",
    "    y = [0,1],\n",
    "    name = 'Reference',\n",
    "    line = dict(\n",
    "        color = ('rgba(255, 0, 0, 0.5)'),\n",
    "        width = 4,\n",
    "        dash = 'dash')\n",
    ")\n",
    "data = [trace0,trace1]\n",
    "layout = go.Layout(\n",
    "    title = 'ROC Curve',\n",
    "    xaxis=dict(title='False Positive Rate'),\n",
    "    yaxis=dict(title='True Positive Rate'))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Solve a Multi-class Classification Problem\n",
    "\n",
    "- can we predict whether a unit will fail within different windows?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Prepare data prior to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redundant sensor values\n",
    "multiclassTrainData = leakageDroppedTrainData.drop(redundantCols, axis = 1)\n",
    "conditions = [\n",
    "    (multiclassTrainData['RUL'] <= 15),\n",
    "    (multiclassTrainData['RUL'] > 15) & (multiclassTrainData['RUL'] <= 30),\n",
    "    (multiclassTrainData['RUL'] > 30)]\n",
    "choices = [2,1,0]\n",
    "multiclassTrainData['label'] = np.select(conditions, choices, default=0)\n",
    "multiclassTrainData = multiclassTrainData.drop(['RUL'],axis=1)\n",
    "\n",
    "# set up features and target variable \n",
    "MCY = multiclassTrainData['label']\n",
    "MCX = multiclassTrainData.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Train a multi-class random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(MCX, MCY, test_size=0.2, random_state=7)\n",
    "\n",
    "randomForestClassifier = ensemble.RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
    "randomForestClassifier.fit(trainX, trainY)\n",
    "predY = randomForestClassifier.predict(testX)\n",
    "predYProb = randomForestClassifier.predict_proba(testX)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testY.value_counts())\n",
    "print(\"Confusion Matrix\")\n",
    "confusionMatrix = confusion_matrix(testY, predY)\n",
    "print(confusionMatrix)\n",
    "precisionScore = precision_score(testY, predY, average='weighted')\n",
    "accuracyScore = accuracy_score(testY, predY)\n",
    "recallScore = recall_score(testY, predY, average='weighted')\n",
    "print(\"Precision: \"+\"{:.1%}\".format(precisionScore))\n",
    "print(\"Accuracy: \"+\"{:.1%}\".format(accuracyScore))\n",
    "print(\"Recall: \"+\"{:.1%}\".format(recallScore))\n",
    "print(classification_report(testY, predY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['figure.figsize'] = [10,10]\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plot_confusion_matrix(confusionMatrix, normalize = True, classes=[\"No failure within 30 cycles\",\"Failure within 15-30 cycles\",\"Failure within 15 cycles\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Feature Engineering\n",
    "\n",
    "- use a moving-average window to filter out noise\n",
    "- calculate standard deviation of the moving-average window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "# add rolling mean and standard deviation\n",
    "\n",
    "windowSize = 5 \n",
    "w0 = 15\n",
    "w1 = 30\n",
    "#redundantCols = ['BurnerFuelAirRatio','EnginePresRatio','DemandFanSpeed','FanInletPres','DemandCorrFanSpeed','FanInletTemp']\n",
    "newSensorCols = [c for c in sensorCols if c not in redundantCols]\n",
    "FETrainData = trainData[['UnitNumber','Cycle','RUL']+newSensorCols]\n",
    "#FETrainData = FETrainData[FETrainData['UnitNumber']==4]\n",
    "# apply rolling mean window\n",
    "MASensorCols = [c+'_MA' for c in newSensorCols]\n",
    "SDSensorCols = [c+'_SD' for c in newSensorCols]\n",
    "print(newSensorCols)\n",
    "grouped = FETrainData.groupby('UnitNumber')\n",
    "# for pandas version 0.18, use this:\n",
    "for col in newSensorCols:\n",
    "    FETrainData['%s_MA'%col] = grouped[col].apply(lambda g: g.rolling(window=windowSize, min_periods=0).mean())\n",
    "    FETrainData['%s_SD'%col] = grouped[col].apply(lambda g: g.rolling(window=windowSize, min_periods=0).std())\n",
    "\n",
    "conditions = [\n",
    "    (FETrainData['RUL'] <= w0),\n",
    "    (FETrainData['RUL'] > w0) & (FETrainData['RUL'] <= w1),\n",
    "    (FETrainData['RUL'] > w1)]\n",
    "choices = [2,1,0]\n",
    "FETrainData['label'] = np.select(conditions, choices, default=0)\n",
    "FETrainData = FETrainData.dropna() # don't drop leakage values yet; we need them later\n",
    "\n",
    "# set up features and target variable \n",
    "\n",
    "FEMCY = FETrainData['label']\n",
    "FEMCX = FETrainData.drop(['label'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Re-train with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class random forest classification\n",
    "trainX, testX, trainY, testY = train_test_split(FEMCX, FEMCY, test_size=0.2, random_state=7)\n",
    "LDTrainX = trainX.drop(['UnitNumber','Cycle','RUL'],axis=1)\n",
    "LDTestX = testX.drop(['UnitNumber','Cycle','RUL'],axis=1)\n",
    "\n",
    "randomForestClassifier = ensemble.RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 42)\n",
    "randomForestClassifier.fit(LDTrainX, trainY)\n",
    "predY = randomForestClassifier.predict(LDTestX)\n",
    "predYProb = randomForestClassifier.predict_proba(LDTestX)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testY.value_counts())\n",
    "print(\"Confusion Matrix\")\n",
    "confusionMatrix = confusion_matrix(testY, predY)\n",
    "print(confusionMatrix)\n",
    "precisionScore = precision_score(testY, predY, average='weighted')\n",
    "accuracyScore = accuracy_score(testY, predY)\n",
    "recallScore = recall_score(testY, predY, average='weighted')\n",
    "print(\"Precision: \"+\"{:.1%}\".format(precisionScore))\n",
    "print(\"Accuracy: \"+\"{:.1%}\".format(accuracyScore))\n",
    "print(\"Recall: \"+\"{:.1%}\".format(recallScore))\n",
    "print(classification_report(testY, predY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['figure.figsize'] = [10,10]\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plot_confusion_matrix(confusionMatrix, normalize = True, classes=[\"No failure within %d cycles\"%w1,\"Failure within %d-%d cycles\"%(w0,w1),\"Failure within %d cycles\"%w0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Calculate Metrics\n",
    "\n",
    "- calculate uptime gain: how many more cycles can be gained by scheduling maintenance after 1st warning or after 1st alarm\n",
    "- what is the maximum theoretical gain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percent uptime gain\n",
    "# assume default maintenance is scheduled every 125 cycles\n",
    "\n",
    "# calculate total cycles run prior to default maintenance\n",
    "scheduledMaintenance = 125 # i.e. each unit runs this many times before maintenance is scheduled\n",
    "numUnits = 100\n",
    "defaultCycles = scheduledMaintenance*numUnits\n",
    "\n",
    "# find when a warning was first issued in the test data\n",
    "\n",
    "evalData = testX.copy() # copy the randomized test data\n",
    "evalData['label'] = predY # append the prediction\n",
    "\n",
    "# calculate how many more cycles can be gained by scheduling maintenance after 1st warning\n",
    "# for each unit, get the rows with predicted label '1' (Warning)\n",
    "# then get the 1st occurrence (1st warning)\n",
    "# sum it all up\n",
    "\n",
    "# calculate how many more cycles can be gained by scheduling maintenance after 1st warning\n",
    "firstWarningCycles = evalData.groupby('UnitNumber').apply(lambda g: g[g['label']==1].sort_values(by='Cycle').head(1))['Cycle'].sum()\n",
    "\n",
    "# calculate how many more cycles can be gained by scheduling maintenance after 1st critical alert\n",
    "firstAlarmCycles = evalData.groupby('UnitNumber').apply(lambda g: g[g['label']==2].sort_values(by='Cycle').head(1))['Cycle'].sum()\n",
    "\n",
    "# calculate how many more cycles can be gained by scheduling maintenance 1 cycle before failure\n",
    "maxTheoreticalCycles = trainData.groupby('UnitNumber').apply(lambda g: g[g['RUL']==1].sort_values(by='Cycle').tail(1))['Cycle'].sum()\n",
    "\n",
    "firstWarningUptimeGain = 100.0*(firstWarningCycles-defaultCycles)/defaultCycles\n",
    "print('Gain %.1f%% additional uptime by doing maintenance upon first Warning signal.'%firstWarningUptimeGain)\n",
    "firstAlarmUptimeGain = 100.0*(firstAlarmCycles-defaultCycles)/defaultCycles\n",
    "print('Gain %.1f%% additional uptime by doing maintenance upon first Alarm signal.'%firstAlarmUptimeGain)\n",
    "maxTheoreticalUptimeGain = 100.0*(maxTheoreticalCycles-defaultCycles)/defaultCycles\n",
    "print('Gain %.1f%% additional uptime by doing maintenance 1 cycle prior to failure (perfect foresight).'%maxTheoreticalUptimeGain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (IoTFuse 2019 - Azure ML Studio)",
   "language": "python",
   "name": "testmlpy35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
