{"nbformat_minor": 1, "cells": [{"source": "# NASA Turbofan Engine Degradation Analysis - IoTFuse 2019", "cell_type": "markdown", "metadata": {}}, {"source": "## Install the required libraries using `pip install`", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "!pip install matplotlib==1.5.1\n!pip install pandas==0.18\n!pip install numpy==1.11.3\n!pip install seaborn==0.7.1\n!pip install scikit-learn==0.18.1\n!pip install plotly==3.1.0", "outputs": [], "metadata": {"scrolled": true}}, {"source": "## Import the packages", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import plotly\nplotly.tools.set_credentials_file(username='', api_key='')\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (16, 16)\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }<\/style>\"))\n# load necessary packages and view available data\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nsns.set()\nnp.random.seed(7)  \nfrom sklearn import ensemble\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import model_selection\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nimport itertools", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "pd.__version__", "outputs": [], "metadata": {}}, {"source": "## Step 1a: Load the datasets from the workspace\n\n- if you're using Notebooks on Azure ML Studio, use the following to load your dataset\n- make sure you've uploaded the data to your workspace first!", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import azureml\nfrom azureml import Workspace\nws = Workspace()\ntrainData = ws.datasets['RUL_train_FD001.csv'].to_dataframe()", "outputs": [], "metadata": {}}, {"source": "## Step 1b: Load a local dataset\n\n- if you're working locally, use the following to load your dataset\n- make sure you're pointing to the directory where the data is stored", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "trainData = pd.read_csv('../data/CMAPSSData/raw_data/train_FD001.txt', sep=\" \", header=None)\ntestData = pd.read_csv('../data/CMAPSSData/raw_data/test_FD001.txt', sep=\" \", header=None)", "outputs": [], "metadata": {}}, {"source": "## Step 2: Transform your data\n\n- Delete any null columns\n- Set datatypes\n- Change column names to something more readable\n- Calculate Remaining Useful Life (RUL)\n- Remove unnecessary columns", "cell_type": "markdown", "metadata": {}}, {"source": "### I. Delete any null columns", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "trainData.drop(trainData.columns[[26, 27]], axis=1, inplace=True)", "outputs": [], "metadata": {}}, {"source": "### II. Set datatypes", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "trainData = trainData.astype(np.float32)", "outputs": [], "metadata": {}}, {"source": "### III. Change column names to something more readable", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "indexCols =  [\"UnitNumber\",\"Cycle\"]\noperationalSettingCols = [\"Setting1\",\"Setting2\",\"Setting3\"]\nsensorCols =['FanInletTemp','LPCOutletTemp','HPCOutletTemp','LPTOutletTemp','FanInletPres','BypassDuctPres','TotalHPCOutletPres','PhysFanSpeed','PhysCoreSpeed','EnginePresRatio','StaticHPCOutletPres','FuelFlowRatio','CorrFanSpeed','CorrCoreSpeed','BypassRatio','BurnerFuelAirRatio','BleedEnthalpy','DemandFanSpeed','DemandCorrFanSpeed','HPTCoolantBleed','LPTCoolantBleed']\ncols = indexCols + operationalSettingCols + sensorCols\n\ntrainData.columns = cols", "outputs": [], "metadata": {}}, {"source": "### IV. Calculate Remaining Useful Life (RUL)\n\n- group the data by `UnitNumber`\n- evaluate the maximum number of cycles and create a new column called `MaxCycles`\n- calculate `RUL` for every instance: RUL(t) = MaxCycles - Cycle(t)", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "maxCycles = trainData.groupby('UnitNumber')['Cycle'].max().reset_index()\nmaxCycles.columns = ['UnitNumber', 'MaxCycles']\nmergedTrain = trainData.merge(maxCycles, left_on='UnitNumber', right_on='UnitNumber', how='inner')\nRUL = mergedTrain[\"MaxCycles\"] - mergedTrain[\"Cycle\"]\ntrainData = mergedTrain[\"RUL\"] = RUL", "outputs": [], "metadata": {"scrolled": true}}, {"execution_count": null, "cell_type": "code", "source": "# remove unnecessary columns\ntrainData = mergedTrain.drop(\"MaxCycles\", axis=1)", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# visualize how features vary with RUL\nfeaturePlot = sns.PairGrid(data=trainData.query('UnitNumber < 15'),\n                       x_vars='RUL',\n                       y_vars=operationalSettingCols+sensorCols,\n                       hue=\"UnitNumber\", size=5, aspect=2)\nfeaturePlot = featurePlot.map(plt.scatter, alpha=0.5)\nfeaturePlot = featurePlot.set(xlim=(400,0))\nfeaturePlot = featurePlot.add_legend()", "outputs": [], "metadata": {"scrolled": true}}, {"execution_count": null, "cell_type": "code", "source": "OpSettingsPlot = sns.pairplot(data=trainData.query('UnitNumber < 15'),\n                              x_vars=operationalSettingCols,\n                              y_vars=sensorCols,\n                              hue=\"UnitNumber\", size=4, aspect=2)", "outputs": [], "metadata": {}}, {"source": "## Step 3: Feature Extraction\n\n- Remove features that can potentially cause target leakage\n- Evaluate feature importance using random forest regression\n- Remove redundant features based on above analysis", "cell_type": "markdown", "metadata": {}}, {"source": "### I. Remove features that can potentially cause target leakage", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "leakageCols = ['UnitNumber', 'Cycle', 'Setting1', 'Setting2', 'Setting3']  \nleakageDroppedTrainData = trainData.drop(leakageCols, axis=1)", "outputs": [], "metadata": {}}, {"source": "### II. Evaluate feature importance using random forest regression", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# set up features and target variable \nFIY = leakageDroppedTrainData['RUL']\nFIX = leakageDroppedTrainData.drop(['RUL'], axis = 1)\n\nrandomForestRegressor = ensemble.RandomForestRegressor(n_estimators = 200, max_depth = 20)\nrandomForestRegressor.fit(FIX, FIY)\npredY = randomForestRegressor.predict(FIX)", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# graph feature importance\nfeatureImportance = randomForestRegressor.feature_importances_\nfeatureIDs = np.argsort(featureImportance)[::-1]\nfeatureNames = FIX.columns    \nf, ax = plt.subplots(figsize=(11, 9))\nplt.title(\"Feature Importance\", fontsize = 20)\nplt.bar(range(FIX.shape[1]), featureImportance[featureIDs], color=\"b\", align=\"center\")\nlabelSet = {id:label for id,label in zip(range(len(featureNames)),featureNames)}\nplt.xticks(range(FIX.shape[1]), [labelSet[id] for id in featureIDs])\nplt.xticks(rotation=-60)\nplt.xlim([-1, FIX.shape[1]])\nplt.ylabel(\"Feature Importance Score\", fontsize = 18)\nplt.xlabel(\"Feature\", fontsize = 18)\nplt.show()\n# list feature importance\nimportant_features = pd.Series(data=randomForestRegressor.feature_importances_,index=FIX.columns)\nimportant_features.sort_values(ascending=False,inplace=True)\ndisplay(important_features)", "outputs": [], "metadata": {}}, {"source": "### III. Remove redundant features based on above analysis", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "redundantCols = list(important_features[important_features<0.0001].index)\nprint(redundantCols)", "outputs": [], "metadata": {}}, {"source": "## Step 4: Solve a Regression Problem\n\n- can we predict RUL (in cycles)?", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "regTrainData = leakageDroppedTrainData.drop(redundantCols, axis = 1)\nregTestData = leakageDroppedTestData.drop(redundantCols, axis=1)\n\n# impute data if needed\n\nnumericData = regTrainData.select_dtypes(exclude=['object'])\nfor col in numericData.columns:\n    if pd.isnull(numericData[col]).sum() > 0:\n        numericData[\"%s_mi\" % (col)] = pd.isnull(numericData[col])\n        median = numericData[col].median()\n        numericData[col] = numericData[col].apply(lambda x: median if pd.isnull(x) else x)\n\n# set up features and target variable \n\nRY = numericData['RUL']\nRX = numericData.drop(['RUL'], axis = 1)", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# random forest regression\ntrainX, testX, trainY, testY = train_test_split(RX, RY, test_size=0.2, random_state=7)\n\nrandomForestRegressor = ensemble.RandomForestRegressor()\npipeline = Pipeline(steps=[('standardize', preprocessing.StandardScaler()),\n                           ('model', randomForestRegressor) ])\n# model tuning\ntest_min_samples_leaf = [2, 10, 25, 50, 100]\ntest_max_depth = [7, 8, 9, 10, 11, 12]\n# run the model using gridsearch, select the model with best search\noptimizedRandomForestRegressor = GridSearchCV(estimator=pipeline,\n                                              cv=model_selection.KFold(5),\n                                              param_grid=dict(model__min_samples_leaf = test_min_samples_leaf, model__max_depth = test_max_depth),\n                                              scoring = 'neg_mean_squared_error',\n                                              verbose = 1,\n                                              n_jobs = -1)\noptimizedRandomForestRegressor.fit(trainX, trainY)\nprint(optimizedRandomForestRegressor.best_estimator_)\npredY = optimizedRandomForestRegressor.predict(testX)\nprint(\"Mean Squared Error: \", mean_squared_error(testY, predY))\nprint(\"Mean Absolute Error: \", mean_absolute_error(testY, predY))\nprint(\"Coefficient of Determination (R2): \", r2_score(testY, predY))", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# plot actual vs predicted Remaining Useful Life\ntrace0 = go.Scatter(\n    x = testY,\n    y = predY,\n    mode = 'markers',\n    name = 'RUL',\n    marker = dict(color='rgb(22, 96, 167)')\n)\ntrace1 = go.Scatter(\n    x = testY,\n    y = testY,\n    name = 'Reference',\n    line = dict(\n        color = ('rgba(0, 0, 0, 0.2)'),\n        width = 4,\n        dash = 'dash')\n)\ndata = [trace1,trace0]\nlayout = go.Layout(\n    title = 'Actual vs. Predicted Useful Remaining Life (Cycles)',\n    xaxis=dict(title='Actual Remaining Useful Life'),\n    yaxis=dict(title='Predicted Remaining Useful Life'))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)", "outputs": [], "metadata": {}}, {"source": "## Step 5: Solve a Classification Problem\n\n- can we identify when unit is within its last 15 cycles?", "cell_type": "markdown", "metadata": {}}, {"source": "### I. Prepare data prior to training", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "leakageDroppedTrainData['15_Cycles'] = np.where(leakageDroppedTrainData['RUL'] <= 15, 1, 0 )\n# remove redundant sensors and RUL\nbinaryTrainData = leakageDroppedTrainData.drop(redundantCols+['RUL'], axis = 1)\n\n# impute data if needed\nnumericData = binaryTrainData.select_dtypes(exclude=['object'])\nfor col in numericData.columns:\n    if pd.isnull(numericData[col]).sum() > 0:\n        numericData[\"%s_mi\" % (col)] = pd.isnull(numericData[col])\n        median = numericData[col].median()\n        numericData[col] = numericData[col].apply(lambda x: median if pd.isnull(x) else x)\nY = numericData['15_Cycles']\nX = numericData.drop(['15_Cycles'], axis = 1)", "outputs": [], "metadata": {}}, {"source": "### II. Train", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# random forest classification\ntrainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2, random_state=7)\nrandomForestClassifier = ensemble.RandomForestClassifier()\npipeline = Pipeline(steps=[('standardize', preprocessing.StandardScaler()),\n                           ('model', randomForestClassifier) ])\n# model tuning\ntest_min_samples_leaf = [2, 25, 50]\ntest_max_depth = [8, 9, 10, 12]\n# run the model using gridsearch, select the model with best search\nfrom sklearn.model_selection import GridSearchCV\noptimizedRandomForestClassifier = GridSearchCV(estimator=pipeline,\n                            cv=model_selection.KFold(5),\n                            param_grid =dict(model__min_samples_leaf = test_min_samples_leaf, model__max_depth = test_max_depth),\n                            scoring = 'roc_auc',\n                            verbose = 1,\n                            n_jobs = -1)\noptimizedRandomForestClassifier.fit(trainX, trainY)\npredY = optimizedRandomForestClassifier.predict(testX)\npredYProb = optimizedRandomForestClassifier.predict_proba(testX)[:, 1]\nprint(optimizedRandomForestClassifier.best_estimator_)", "outputs": [], "metadata": {}}, {"source": "### III. Plot confusion matrix", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "print(\"Confusion Matrix\")\nconfusionMatrix = confusion_matrix(testY, predY)\nprint(confusionMatrix)\nprecisionScore = precision_score(testY, predY)\naccuracyScore = accuracy_score(testY, predY)\nrecallScore = recall_score(testY, predY)\nprint(\"Precision: \"+\"{:.1%}\".format(precisionScore))\nprint(\"Accuracy: \"+\"{:.1%}\".format(accuracyScore))\nprint(\"Recall: \"+\"{:.1%}\".format(recallScore))\nprint(classification_report(testY, predY))", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "font = {'family' : 'DejaVu Sans',\n        'weight' : 'bold',\n        'size'   : 36}\n\nmatplotlib.rc('font', **font)\nmatplotlib.rcParams['figure.figsize'] = [14,10]\n\nfpr, tpr, threshold = metrics.roc_curve(testY, predYProb)\nroc_auc = metrics.auc(fpr, tpr)\nplt.title('ROC curve',fontsize=18)\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate',fontsize=18)\nplt.xlabel('False Positive Rate',fontsize=18)\nplt.show()", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title,fontsize=18)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label',fontsize=18)\n    plt.xlabel('Predicted label',fontsize=18)\n    plt.tight_layout()\n\nfont = {'family' : 'DejaVu Sans',\n        'weight' : 'bold',\n        'size'   : 22}\n\nmatplotlib.rc('font', **font)\nmatplotlib.rcParams['figure.figsize'] = [10,10]\nplt.rcParams[\"axes.grid\"] = False\nplot_confusion_matrix(confusionMatrix, normalize = True, classes=[\"Failure within 15 days\",\"No failure\"])", "outputs": [], "metadata": {}}, {"source": "### IV. Plot ROC curve", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "trace0 = go.Scatter(\n    x = fpr,\n    y = tpr,\n    mode = 'lines',\n    name = 'AUC = %0.2f' % roc_auc,\n)\ntrace1 = go.Scatter(\n    x = [0,1],\n    y = [0,1],\n    name = 'Reference',\n    line = dict(\n        color = ('rgba(255, 0, 0, 0.5)'),\n        width = 4,\n        dash = 'dash')\n)\ndata = [trace0,trace1]\nlayout = go.Layout(\n    title = 'ROC Curve',\n    xaxis=dict(title='False Positive Rate'),\n    yaxis=dict(title='True Positive Rate'))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)", "outputs": [], "metadata": {}}, {"source": "## Step 4: Solve a Multi-class Classification Problem\n\n- can we predict whether a unit will fail within window 1, window 2 or window 3?", "cell_type": "markdown", "metadata": {}}, {"source": "### I. Prepare data prior to training", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# remove redundant sensor values\nmulticlassTrainData = leakageDroppedTrainData.drop(redundantCols, axis = 1)\n\nconditions = [\n    (multiclassTrainData['RUL'] <= 15),\n    (multiclassTrainData['RUL'] > 15) & (multiclassTrainData['RUL'] <= 30),\n    (multiclassTrainData['RUL'] > 30)]\nchoices = [2,1,0]\nmulticlassTrainData['label'] = np.select(conditions, choices, default=0)\nmulticlassTrainData = multiclassTrainData.drop(['RUL'],axis=1)\n\n# set up features and target variable \n\nMCY = multiclassTrainData['label']\nMCX = multiclassTrainData.drop(['label'], axis = 1)", "outputs": [], "metadata": {}}, {"source": "### II. Train", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# multi-class random forest classification\ntrainX, testX, trainY, testY = train_test_split(MCX, MCY, test_size=0.2, random_state=7)\n\nrandomForestClassifier = ensemble.RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\nrandomForestClassifier.fit(trainX, trainY)\npredY = randomForestClassifier.predict(testX)\npredYProb = randomForestClassifier.predict_proba(testX)[:, 1]", "outputs": [], "metadata": {}}, {"source": "### III. Plot confusion matrix", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "print(testY.value_counts())\nprint(\"Confusion Matrix\")\nconfusionMatrix = confusion_matrix(testY, predY)\nprint(confusionMatrix)\nprecisionScore = precision_score(testY, predY, average='weighted')\naccuracyScore = accuracy_score(testY, predY)\nrecallScore = recall_score(testY, predY, average='weighted')\nprint(\"Precision: \"+\"{:.1%}\".format(precisionScore))\nprint(\"Accuracy: \"+\"{:.1%}\".format(accuracyScore))\nprint(\"Recall: \"+\"{:.1%}\".format(recallScore))\nprint(classification_report(testY, predY))", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "font = {'family' : 'DejaVu Sans',\n        'weight' : 'bold',\n        'size'   : 22}\n\nmatplotlib.rc('font', **font)\nmatplotlib.rcParams['figure.figsize'] = [10,10]\nplt.rcParams[\"axes.grid\"] = False\nplot_confusion_matrix(confusionMatrix, normalize = True, classes=[\"No failure within 30 cycles\",\"Failure within 15-30 cycles\",\"Failure within 15 cycles\"])", "outputs": [], "metadata": {}}, {"source": "### III. Plot confusion matrix", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# feature engineering\n# add rolling mean and standard deviation\n\nwindowSize = 5 \nw0 = 15\nw1 = 30\nredundantCols = ['BurnerFuelAirRatio','EnginePresRatio','DemandFanSpeed','FanInletPres','DemandCorrFanSpeed','FanInletTemp']\nnewSensorCols = [c for c in sensorCols if c not in redundantCols]\nFETrainData = trainData[['UnitNumber','Cycle','RUL']+newSensorCols]\n#FETrainData = FETrainData[FETrainData['UnitNumber']==4]\n# apply rolling mean window\nMASensorCols = [c+'_MA' for c in newSensorCols]\nSDSensorCols = [c+'_SD' for c in newSensorCols]\nprint(newSensorCols)\ngrouped = FETrainData.groupby('UnitNumber')\n# for pandas version 0.18, use this:\nfor col in newSensorCols:\n    FETrainData['%s_MA'%col] = grouped[col].apply(lambda g: g.rolling(window=windowSize, min_periods=0).mean())\n    FETrainData['%s_SD'%col] = grouped[col].apply(lambda g: g.rolling(window=windowSize, min_periods=0).mean())\n\nconditions = [\n    (FETrainData['RUL'] <= w0),\n    (FETrainData['RUL'] > w0) & (FETrainData['RUL'] <= w1),\n    (FETrainData['RUL'] > w1)]\nchoices = [2,1,0]\nFETrainData['label'] = np.select(conditions, choices, default=0)\nFETrainData = FETrainData.dropna() # don't drop leakage values yet; we need them later\n\n# set up features and target variable \n\nFEMCY = FETrainData['label']\nFEMCX = FETrainData.drop(['label'], axis = 1)\n", "outputs": [], "metadata": {"scrolled": true}}, {"source": "### IV. Re-train with new features", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# multi-class random forest classification\ntrainX, testX, trainY, testY = train_test_split(FEMCX, FEMCY, test_size=0.2, random_state=7)\nLDTrainX = trainX.drop(['UnitNumber','Cycle','RUL'],axis=1)\nLDTestX = testX.drop(['UnitNumber','Cycle','RUL'],axis=1)\n\nrandomForestClassifier = ensemble.RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\nrandomForestClassifier.fit(LDTrainX, trainY)\npredY = randomForestClassifier.predict(LDTestX)\npredYProb = randomForestClassifier.predict_proba(LDTestX)[:, 1]", "outputs": [], "metadata": {}}, {"source": "### VI. Plot confusion matrix", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "print(testY.value_counts())\nprint(\"Confusion Matrix\")\nconfusionMatrix = confusion_matrix(testY, predY)\nprint(confusionMatrix)\nprecisionScore = precision_score(testY, predY, average='weighted')\naccuracyScore = accuracy_score(testY, predY)\nrecallScore = recall_score(testY, predY, average='weighted')\nprint(\"Precision: \"+\"{:.1%}\".format(precisionScore))\nprint(\"Accuracy: \"+\"{:.1%}\".format(accuracyScore))\nprint(\"Recall: \"+\"{:.1%}\".format(recallScore))\nprint(classification_report(testY, predY))", "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "font = {'family' : 'DejaVu Sans',\n        'weight' : 'bold',\n        'size'   : 22}\n\nmatplotlib.rc('font', **font)\nmatplotlib.rcParams['figure.figsize'] = [10,10]\nplt.rcParams[\"axes.grid\"] = False\nplot_confusion_matrix(confusionMatrix, normalize = True, classes=[\"No failure within %d cycles\"%w1,\"Failure within %d-%d cycles\"%(w0,w1),\"Failure within %d cycles\"%w0])", "outputs": [], "metadata": {}}, {"source": "## Step 5: Calculate Metrics\n\n- calculate how many more cycles can be gained by scheduling maintenance after 1st warning, etc.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# calculate percent uptime gain\n# assume default maintenance is scheduled every 125 cycles\n\n# calculate total cycles run prior to default maintenance\nscheduledMaintenance = 125 # i.e. each unit runs this many times before maintenance is scheduled\nnumUnits = 100\ndefaultCycles = scheduledMaintenance*numUnits\n\n# find when a warning was first issued in the test data\n\nevalData = testX.copy() # copy the randomized test data\nevalData['label'] = predY # append the prediction\n\n# calculate how many more cycles can be gained by scheduling maintenance after 1st warning\n# for each unit, get the rows with predicted label '1' (Warning)\n# then get the 1st occurrence (1st warning)\n# sum it all up\nfirstWarningCycles = evalData.groupby('UnitNumber').apply(lambda g: g[g['label']==1].sort_values(by='Cycle').head(1))['Cycle'].sum()\n# calculate how many more cycles can be gained by scheduling maintenance after 1st warning\nfirstAlarmCycles = evalData.groupby('UnitNumber').apply(lambda g: g[g['label']==2].sort_values(by='Cycle').head(1))['Cycle'].sum()\n# calculate how many more cycles can be gained by scheduling maintenance 1 cycle before failure\nmaxTheoreticalCycles = trainData.groupby('UnitNumber').apply(lambda g: g[g['RUL']==1].sort_values(by='Cycle').tail(1))['Cycle'].sum()\n\nfirstWarningUptimeGain = 100.0*(firstWarningCycles-defaultCycles)/defaultCycles\nprint('Gain %.1f%% additional uptime by doing maintenance upon first Warning signal.'%firstWarningUptimeGain)\nfirstAlarmUptimeGain = 100.0*(firstAlarmCycles-defaultCycles)/defaultCycles\nprint('Gain %.1f%% additional uptime by doing maintenance upon first Alarm signal.'%firstAlarmUptimeGain)\nmaxTheoreticalUptimeGain = 100.0*(maxTheoreticalCycles-defaultCycles)/defaultCycles\nprint('Gain %.1f%% additional uptime by doing maintenance 1 cycle prior to failure (perfect foresight).'%maxTheoreticalUptimeGain)", "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.4.5", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}}